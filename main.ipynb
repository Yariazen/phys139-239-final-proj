{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "580fd59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a bunch of import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from plotting import normalize_image, plot_image_array, plot_confusion_matrix, plot_model_history\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2319d34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set various paths\n",
    "data_path = os.path.join(sys.path[0], 'galaxy-zoo-the-galaxy-challenge/data')\n",
    "training_path = os.path.join(data_path, 'images_training_rev1')\n",
    "test_path = os.path.join(data_path, 'images_test_rev1')\n",
    "\n",
    "# find file names\n",
    "training_file_names = os.listdir(training_path)\n",
    "test_file_names = os.listdir(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebbdae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv data\n",
    "all_ones_benchmark = pd.read_csv(os.path.join(data_path, 'all_ones_benchmark.csv'), dtype=str)\n",
    "all_zeros_benchmark = pd.read_csv(os.path.join(data_path, 'all_zeros_benchmark.csv'), dtype=str)\n",
    "central_pixel_benchmark = pd.read_csv(os.path.join(data_path, 'central_pixel_benchmark.csv'), dtype=str)\n",
    "training_solutions_rev1 = pd.read_csv(os.path.join(data_path, 'training_solutions_rev1.csv'), dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f748c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Evelyn\n",
    "training_path = os.path.join(sys.path[0], 'images_training_rev1')\n",
    "test_path = os.path.join(sys.path[0], 'images_test_rev1')\n",
    "training_file_names = os.listdir(training_path)\n",
    "test_file_names = os.listdir(test_path)\n",
    "\n",
    "\n",
    "all_ones_benchmark = pd.read_csv(os.path.join(sys.path[0], 'all_ones_benchmark.csv'), dtype=str)\n",
    "all_zeros_benchmark = pd.read_csv(os.path.join(sys.path[0], 'all_zeros_benchmark.csv'), dtype=str)\n",
    "central_pixel_benchmark = pd.read_csv(os.path.join(sys.path[0], 'central_pixel_benchmark.csv'), dtype=str)\n",
    "training_solutions_rev1 = pd.read_csv(os.path.join(sys.path[0], 'training_solutions_rev1.csv'), dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e2da426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training images + sol\n",
    "training_img = []\n",
    "training_img_sol = []\n",
    "\n",
    "for file in training_file_names[:1500]: \n",
    "    # extract training image\n",
    "    training_img.append(cv2.imread(os.path.join(training_path, file)))\n",
    "    \n",
    "    # extract corresponding galaxy class probabilities from answer key\n",
    "    galaxy_id = file[:6]\n",
    "    sol_data = training_solutions_rev1.loc[training_solutions_rev1['GalaxyID'] == galaxy_id]\n",
    "    training_img_sol.append(np.array(sol_data.iloc[0].tolist()[1:]))\n",
    "\n",
    "# convert to numpy arrays\n",
    "training_img = np.array(training_img)\n",
    "training_img_sol = np.array(training_img_sol)\n",
    "\n",
    "# load testing images\n",
    "test_img = []\n",
    "for file in test_file_names[:10]:\n",
    "    test_img.append(cv2.imread(os.path.join(test_path, file)))\n",
    "test_img = np.array(test_img)\n",
    "\n",
    "# class types (I'm sure there's a better way of doing this)\n",
    "galaxy_class_labels = np.array([\"Class1.1\", \"Class1.2\", \"Class1.3\", \"Class2.1\", \"Class2.2\", \"Class3.1\", \"Class3.2\", \n",
    "                \"Class4.1\", \"Class4.2\", \"Class5.1\", \"Class5.2\", \"Class5.3\", \"Class5.4\", \"Class6.1\",\n",
    "                \"Class6.2\", \"Class7.1\", \"Class7.2\", \"Class7.3\", \"Class8.1\", \"Class8.2\", \"Class8.3\",\n",
    "                \"Class8.4\", \"Class8.5\", \"Class8.6\", \"Class8.7\", \"Class9.1\", \"Class9.2\", \"Class9.3\",\n",
    "                \"Class10.1\", \"Class10.2\", \"Class10.3\", \"Class11.1\", \"Class11.2\", \"Class11.3\", \"Class11.4\",\n",
    "                \"Class11.5\", \"Class11.6\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9a2eed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 21:26:35.835711: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-14 21:26:37.009325: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.9/site-packages/cv2/../../lib64:/opt/conda/pkgs/cudnn-8.1.0.77-h90431f1_0/lib/:/opt/conda/pkgs/cudatoolkit-11.2.2-he111cf0_8/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-14 21:26:37.009467: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.9/site-packages/cv2/../../lib64:/opt/conda/pkgs/cudnn-8.1.0.77-h90431f1_0/lib/:/opt/conda/pkgs/cudatoolkit-11.2.2-he111cf0_8/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-14 21:26:37.009481: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the training (1200); test (1200); and validation (300) data sets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def reshape_arrays(data, labels):\n",
    "    \"\"\"reshape arrays for Keras\"\"\"\n",
    "    data = data.reshape(-1, 424, 424, 3)\n",
    "    labels = to_categorical(labels)\n",
    "    return data, labels\n",
    "\n",
    "# split the samples into training, validation and, test data sets:\n",
    "train_frac = 0.8\n",
    "val_frac = 0.2\n",
    "\n",
    "# Note: we have to use train_test_split twice\n",
    "data_train_val, data_test, class_train_val, class_test = train_test_split(training_img, training_img_sol, test_size=None)\n",
    "\n",
    "data_train, data_val, class_train, class_val = train_test_split(\n",
    "    training_img, training_img_sol, test_size=val_frac / (train_frac + val_frac)\n",
    ")\n",
    "\n",
    "class_train = np.asarray(class_train, dtype=np.float64)\n",
    "\n",
    "'''The following commented-out code throws an error'''\n",
    "#data_train, class_train = reshape_arrays(data_train, class_train)\n",
    "#data_val, class_val = reshape_arrays(data_val, class_val)\n",
    "#data_test, class_test = reshape_arrays(data_test, class_test)\n",
    "\n",
    "print(\n",
    "    f\"Number of samples in the training ({data_train.shape[0]}); test ({data_train.shape[0]}); and validation ({data_val.shape[0]}) data sets\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1513d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "'''VGG6'''\n",
    "def vgg6(input_shape=(424, 424, 3), n_classes: int = 37):\n",
    "    \"\"\"\n",
    "        VGG6\n",
    "    :param input_shape:\n",
    "    :param n_classes:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential(name=\"VGG6\")\n",
    "    # input: 21x21 images with 1 channel -> (21, 21, 1) tensors.\n",
    "    # this applies 16 convolution filters of size 3x3 each.\n",
    "    model.add(Conv2D(16, (3, 3), activation=\"relu\", input_shape=input_shape, name=\"conv1\"))\n",
    "    model.add(Conv2D(16, (3, 3), activation=\"relu\", name=\"conv2\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation=\"relu\", name=\"conv3\"))\n",
    "    model.add(Conv2D(32, (3, 3), activation=\"relu\", name=\"conv4\"))\n",
    "    model.add(BatchNormalization(axis=3, name=\"bn_2\"))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(256, activation=\"relu\", name=\"fc_1\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    # output layer\n",
    "    activation = \"sigmoid\" if n_classes == 1 else \"softmax\"\n",
    "    model.add(Dense(n_classes, activation=activation, name=\"fc_out\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c3d8364",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''RESNET50'''\n",
    "## Create Neural Network w/ Keras (ResNet50)\n",
    "# Based on https://github.com/priya-dwivedi/Deep-Learning/blob/master/resnet_keras/Residual_Networks_yourself.ipynb\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Add,\n",
    "    Dense,\n",
    "    Activation,\n",
    "    ZeroPadding2D,\n",
    "    BatchNormalization,\n",
    "    Flatten,\n",
    "    Conv2D,\n",
    "    AveragePooling2D,\n",
    "    MaxPooling2D,\n",
    "    GlobalMaxPooling2D,\n",
    ")\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.set_image_data_format(\"channels_last\")\n",
    "\n",
    "\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 3\n",
    "\n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # defining name basis\n",
    "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
    "    bn_name_base = \"bn\" + str(stage) + block + \"_branch\"\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value. You'll need this later to add back to the main path.\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path\n",
    "    X = Conv2D(\n",
    "        filters=F1,\n",
    "        kernel_size=(1, 1),\n",
    "        strides=(1, 1),\n",
    "        padding=\"valid\",\n",
    "        name=conv_name_base + \"2a\",\n",
    "        kernel_initializer=glorot_uniform(seed=0),\n",
    "    )(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + \"2a\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(\n",
    "        filters=F2,\n",
    "        kernel_size=(f, f),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        name=conv_name_base + \"2b\",\n",
    "        kernel_initializer=glorot_uniform(seed=0),\n",
    "    )(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + \"2b\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(\n",
    "        filters=F3,\n",
    "        kernel_size=(1, 1),\n",
    "        strides=(1, 1),\n",
    "        padding=\"valid\",\n",
    "        name=conv_name_base + \"2c\",\n",
    "        kernel_initializer=glorot_uniform(seed=0),\n",
    "    )(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + \"2c\")(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation(\"relu\")(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def convolutional_block(X, f, filters, stage, block, s=2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "\n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # defining name basis\n",
    "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
    "    bn_name_base = \"bn\" + str(stage) + block + \"_branch\"\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path\n",
    "    X = Conv2D(F1, (1, 1), strides=(s, s), name=conv_name_base + \"2a\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + \"2a\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(\n",
    "        filters=F2,\n",
    "        kernel_size=(f, f),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        name=conv_name_base + \"2b\",\n",
    "        kernel_initializer=glorot_uniform(seed=0),\n",
    "    )(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + \"2b\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(\n",
    "        filters=F3,\n",
    "        kernel_size=(1, 1),\n",
    "        strides=(1, 1),\n",
    "        padding=\"valid\",\n",
    "        name=conv_name_base + \"2c\",\n",
    "        kernel_initializer=glorot_uniform(seed=0),\n",
    "    )(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + \"2c\")(X)\n",
    "\n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    X_shortcut = Conv2D(\n",
    "        filters=F3,\n",
    "        kernel_size=(1, 1),\n",
    "        strides=(s, s),\n",
    "        padding=\"valid\",\n",
    "        name=conv_name_base + \"1\",\n",
    "        kernel_initializer=glorot_uniform(seed=0),\n",
    "    )(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + \"1\")(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation(\"relu\")(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def ResNet50(input_shape=(424, 424, 3), classes=37):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name=\"conv1\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=\"bn_conv1\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block=\"a\", s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block=\"b\")\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block=\"c\")\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Stage 3 (≈4 lines)\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block=\"a\", s=2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block=\"b\")\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block=\"c\")\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block=\"d\")\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block=\"a\", s=2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block=\"b\")\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block=\"c\")\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block=\"d\")\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block=\"e\")\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block=\"f\")\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block=\"a\", s=2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block=\"b\")\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block=\"c\")\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation=\"softmax\", name=\"fc\" + str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name=\"ResNet50\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85020f87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGG6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1 (Conv2D)              (None, 422, 422, 16)      448       \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 420, 420, 16)      2320      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 210, 210, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 210, 210, 16)      0         \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 208, 208, 32)      4640      \n",
      "                                                                 \n",
      " conv4 (Conv2D)              (None, 206, 206, 32)      9248      \n",
      "                                                                 \n",
      " bn_2 (BatchNormalization)   (None, 206, 206, 32)      128       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 51, 51, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 51, 51, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 83232)             0         \n",
      "                                                                 \n",
      " fc_1 (Dense)                (None, 256)               21307648  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " fc_out (Dense)              (None, 37)                9509      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,333,941\n",
      "Trainable params: 21,333,877\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 21:26:39.479803: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-14 21:26:40.327063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10405 MB memory:  -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "final_model = vgg6() # for now choose between vgg6() and ResNet50()\n",
    "final_model.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "984cd04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 21:26:42.460500: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inVGG6/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-03-14 21:26:43.989589: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-03-14 21:26:44.539448: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-14 21:26:46.781888: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-14 21:26:46.824193: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.99GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-14 21:26:46.955367: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x55a064f80c30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-14 21:26:46.955471: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2023-03-14 21:26:46.997516: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-14 21:26:47.072897: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-03-14 21:26:47.101618: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-14 21:26:47.196414: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-14 21:26:47.278036: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-14 21:26:47.380033: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-14 21:26:47.568575: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-14 21:26:47.605598: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.99GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-14 21:26:47.737009: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.69GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-14 21:26:47.737065: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.99GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-14 21:26:47.857671: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-14 21:26:48.233779: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.70GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-14 21:26:48.385271: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-14 21:26:48.465482: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.37GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-14 21:26:48.465554: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
      "2023-03-14 21:26:48.964435: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-14 21:26:49.254538: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-14 21:26:49.440064: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-14 21:26:49.530394: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/10 [==>...........................] - ETA: 1:16 - loss: 2.1962 - accuracy: 0.0234"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 21:26:49.797775: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 15s 750ms/step - loss: 1.1308 - accuracy: 0.1558\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 6s 622ms/step - loss: 0.6546 - accuracy: 0.1525\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 6s 611ms/step - loss: 0.6329 - accuracy: 0.1383\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 6s 599ms/step - loss: 0.5652 - accuracy: 0.2333\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 6s 579ms/step - loss: 0.5375 - accuracy: 0.2683\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 6s 590ms/step - loss: 0.5059 - accuracy: 0.2908\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 6s 617ms/step - loss: 0.4800 - accuracy: 0.3133\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 6s 592ms/step - loss: 0.4698 - accuracy: 0.3300\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 6s 595ms/step - loss: 0.4508 - accuracy: 0.3217\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 6s 596ms/step - loss: 0.4364 - accuracy: 0.3350\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 6s 592ms/step - loss: 0.4259 - accuracy: 0.3392\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 6s 590ms/step - loss: 0.4163 - accuracy: 0.3733\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 6s 594ms/step - loss: 0.4075 - accuracy: 0.4117\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 6s 602ms/step - loss: 0.4037 - accuracy: 0.3692\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 6s 598ms/step - loss: 0.4002 - accuracy: 0.4025\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 6s 606ms/step - loss: 0.3951 - accuracy: 0.3883\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 6s 596ms/step - loss: 0.3862 - accuracy: 0.3858\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 6s 600ms/step - loss: 0.3872 - accuracy: 0.3800\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 6s 592ms/step - loss: 0.3817 - accuracy: 0.4008\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 6s 589ms/step - loss: 0.3783 - accuracy: 0.4300\n",
      "12/12 [==============================] - 2s 67ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train model for 20 epochs\n",
    "n_epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "final_model_history = final_model.fit(\n",
    "    data_train,\n",
    "    class_train,\n",
    "    epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    "    validation_data=None,\n",
    "    shuffle=True,\n",
    ")\n",
    "classes = final_model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dce767cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.531033  , 0.389839  , 0.079128  , 0.        , 0.389839  ,\n",
       "        0.        , 0.389839  , 0.20845822, 0.18138078, 0.        ,\n",
       "        0.19650264, 0.12891274, 0.06442323, 0.039942  , 0.960058  ,\n",
       "        0.34028754, 0.19074546, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.039942  , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.20845822, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20845822]),\n",
       " array([0.713851  , 0.268749  , 0.0174    , 0.        , 0.268749  ,\n",
       "        0.12199377, 0.14675523, 0.13818455, 0.13056445, 0.        ,\n",
       "        0.08537618, 0.18337282, 0.        , 0.322795  , 0.677205  ,\n",
       "        0.        , 0.66809529, 0.04575571, 0.18431595, 0.        ,\n",
       "        0.04615968, 0.        , 0.04615968, 0.04615968, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.13818455, 0.        ,\n",
       "        0.        , 0.        , 0.13818455, 0.        , 0.        ,\n",
       "        0.        , 0.        ]),\n",
       " array([0.771744  , 0.190629  , 0.037627  , 0.        , 0.190629  ,\n",
       "        0.        , 0.190629  , 0.        , 0.190629  , 0.        ,\n",
       "        0.09417816, 0.09645084, 0.        , 0.        , 1.        ,\n",
       "        0.64698849, 0.12475551, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]),\n",
       " array([0.223623  , 0.747394  , 0.028983  , 0.        , 0.747394  ,\n",
       "        0.07881046, 0.66858354, 0.33678695, 0.41060705, 0.01795539,\n",
       "        0.37856104, 0.27086455, 0.08001376, 0.268711  , 0.731289  ,\n",
       "        0.18685401, 0.02766328, 0.00910548, 0.02985675, 0.02985675,\n",
       "        0.08957024, 0.08957024, 0.02985675, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.15338052, 0.1226568 ,\n",
       "        0.06074997, 0.10352494, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.23326201]),\n",
       " (1200, 37))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_train[0,:], class_train[26,:], class_train[135,:], class_train[6,:], class_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d61cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a10789d11d8c67e98bd9d36939f7ef03652b69216f681e3f86f003592db452c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
