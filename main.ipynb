{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "580fd59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 15:07:41.781515: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-19 15:07:42.868017: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-19 15:07:42.870817: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-19 15:07:42.870920: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# a bunch of import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from plotting import normalize_image, plot_image_array, plot_confusion_matrix, plot_model_history\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# configure GPU memory options (for Michael)\n",
    "import tensorflow as tf\n",
    "tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10240)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2319d34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set various paths\n",
    "data_path = os.path.join(sys.path[0], 'galaxy-zoo-the-galaxy-challenge/data')\n",
    "training_path = os.path.join(data_path, 'images_training_rev1')\n",
    "test_path = os.path.join(data_path, 'images_test_rev1')\n",
    "\n",
    "# find file names\n",
    "training_file_names = os.listdir(training_path)\n",
    "test_file_names = os.listdir(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ebbdae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv data\n",
    "all_ones_benchmark = pd.read_csv(os.path.join(data_path, 'all_ones_benchmark.csv'), dtype=str)\n",
    "all_zeros_benchmark = pd.read_csv(os.path.join(data_path, 'all_zeros_benchmark.csv'), dtype=str)\n",
    "central_pixel_benchmark = pd.read_csv(os.path.join(data_path, 'central_pixel_benchmark.csv'), dtype=str)\n",
    "training_solutions_rev1 = pd.read_csv(os.path.join(data_path, 'training_solutions_rev1.csv'), dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f748c6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# For Evelyn\\ntraining_path = os.path.join(sys.path[0], 'images_training_rev1')\\ntest_path = os.path.join(sys.path[0], 'images_test_rev1')\\ntraining_file_names = os.listdir(training_path)\\ntest_file_names = os.listdir(test_path)\\n\\n\\nall_ones_benchmark = pd.read_csv(os.path.join(sys.path[0], 'all_ones_benchmark.csv'), dtype=str)\\nall_zeros_benchmark = pd.read_csv(os.path.join(sys.path[0], 'all_zeros_benchmark.csv'), dtype=str)\\ncentral_pixel_benchmark = pd.read_csv(os.path.join(sys.path[0], 'central_pixel_benchmark.csv'), dtype=str)\\ntraining_solutions_rev1 = pd.read_csv(os.path.join(sys.path[0], 'training_solutions_rev1.csv'), dtype=str)\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# For Evelyn\n",
    "training_path = os.path.join(sys.path[0], 'images_training_rev1')\n",
    "test_path = os.path.join(sys.path[0], 'images_test_rev1')\n",
    "training_file_names = os.listdir(training_path)\n",
    "test_file_names = os.listdir(test_path)\n",
    "\n",
    "\n",
    "all_ones_benchmark = pd.read_csv(os.path.join(sys.path[0], 'all_ones_benchmark.csv'), dtype=str)\n",
    "all_zeros_benchmark = pd.read_csv(os.path.join(sys.path[0], 'all_zeros_benchmark.csv'), dtype=str)\n",
    "central_pixel_benchmark = pd.read_csv(os.path.join(sys.path[0], 'central_pixel_benchmark.csv'), dtype=str)\n",
    "training_solutions_rev1 = pd.read_csv(os.path.join(sys.path[0], 'training_solutions_rev1.csv'), dtype=str)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e2da426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training images + sol\n",
    "training_img = []\n",
    "training_img_sol = []\n",
    "\n",
    "for file in training_file_names[:10500]: \n",
    "    # extract training image\n",
    "    training_img.append(cv2.imread(os.path.join(training_path, file)))\n",
    "    \n",
    "    # extract corresponding galaxy class probabilities from answer key\n",
    "    galaxy_id = file[:6]\n",
    "    sol_data = training_solutions_rev1.loc[training_solutions_rev1['GalaxyID'] == galaxy_id]\n",
    "    training_img_sol.append(np.array(sol_data.iloc[0].tolist()[1:]))\n",
    "\n",
    "# convert to numpy arrays\n",
    "training_img = np.array(training_img)\n",
    "training_img_sol = np.array(training_img_sol)\n",
    "\n",
    "# load testing images\n",
    "test_img = []\n",
    "for file in test_file_names[:1000]:\n",
    "    test_img.append(cv2.imread(os.path.join(test_path, file)))\n",
    "test_img = np.array(test_img)\n",
    "\n",
    "# class types (I'm sure there's a better way of doing this)\n",
    "galaxy_class_labels = np.array([\"Class1.1\", \"Class1.2\", \"Class1.3\", \"Class2.1\", \"Class2.2\", \"Class3.1\", \"Class3.2\", \n",
    "                \"Class4.1\", \"Class4.2\", \"Class5.1\", \"Class5.2\", \"Class5.3\", \"Class5.4\", \"Class6.1\",\n",
    "                \"Class6.2\", \"Class7.1\", \"Class7.2\", \"Class7.3\", \"Class8.1\", \"Class8.2\", \"Class8.3\",\n",
    "                \"Class8.4\", \"Class8.5\", \"Class8.6\", \"Class8.7\", \"Class9.1\", \"Class9.2\", \"Class9.3\",\n",
    "                \"Class10.1\", \"Class10.2\", \"Class10.3\", \"Class11.1\", \"Class11.2\", \"Class11.3\", \"Class11.4\",\n",
    "                \"Class11.5\", \"Class11.6\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9a2eed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the training (8400); test (8400); and validation (2100) data sets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def reshape_arrays(data, labels):\n",
    "    \"\"\"reshape arrays for Keras\"\"\"\n",
    "    data = data.reshape(-1, 424, 424, 3)\n",
    "    labels = to_categorical(labels)\n",
    "    return data, labels\n",
    "\n",
    "# split the samples into training, validation and, test data sets:\n",
    "train_frac = 0.8\n",
    "val_frac = 0.2\n",
    "\n",
    "# format the data for NN training\n",
    "data_train_val, data_test, class_train_val, class_test = train_test_split(training_img, training_img_sol, test_size=None)\n",
    "\n",
    "data_train, data_val, class_train, class_val = train_test_split(\n",
    "    training_img, training_img_sol, test_size=val_frac / (train_frac + val_frac)\n",
    ")\n",
    "\n",
    "class_train = np.asarray(class_train, dtype=np.float64)\n",
    "\n",
    "# print number of samples\n",
    "print(\n",
    "    f\"Number of samples in the training ({data_train.shape[0]}); test ({data_train.shape[0]}); and validation ({data_val.shape[0]}) data sets\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1513d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "'''VGG6'''\n",
    "def vgg6(input_shape=(424, 424, 3), n_classes: int = 37):\n",
    "    \"\"\"\n",
    "        VGG6\n",
    "    :param input_shape:\n",
    "    :param n_classes:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential(name=\"VGG6\")\n",
    "    # input: 21x21 images with 1 channel -> (21, 21, 1) tensors.\n",
    "    # this applies 16 convolution filters of size 3x3 each.\n",
    "    model.add(Conv2D(16, (3, 3), activation=\"relu\", input_shape=input_shape, name=\"conv1\"))\n",
    "    model.add(Conv2D(16, (3, 3), activation=\"relu\", name=\"conv2\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation=\"relu\", name=\"conv3\"))\n",
    "    model.add(Conv2D(32, (3, 3), activation=\"relu\", name=\"conv4\"))\n",
    "    model.add(BatchNormalization(axis=3, name=\"bn_2\"))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(256, activation=\"relu\", name=\"fc_1\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    # output layer\n",
    "    activation = \"sigmoid\" if n_classes == 1 else \"softmax\"\n",
    "    model.add(Dense(n_classes, activation=activation, name=\"fc_out\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85020f87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGG6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1 (Conv2D)              (None, 422, 422, 16)      448       \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 420, 420, 16)      2320      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 210, 210, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 210, 210, 16)      0         \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 208, 208, 32)      4640      \n",
      "                                                                 \n",
      " conv4 (Conv2D)              (None, 206, 206, 32)      9248      \n",
      "                                                                 \n",
      " bn_2 (BatchNormalization)   (None, 206, 206, 32)      128       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 51, 51, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 51, 51, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 83232)             0         \n",
      "                                                                 \n",
      " fc_1 (Dense)                (None, 256)               21307648  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " fc_out (Dense)              (None, 37)                9509      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,333,941\n",
      "Trainable params: 21,333,877\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 15:08:19.044836: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-19 15:08:19.045646: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-19 15:08:19.045787: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-19 15:08:19.045881: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-19 15:08:19.266759: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-19 15:08:19.266890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-19 15:08:19.266984: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-19 15:08:19.267056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9637 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "final_model = vgg6() # for now choose between vgg6() and ResNet50()\n",
    "final_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "984cd04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 15:08:19.348144: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 4530355200 exceeds 10% of free system memory.\n",
      "2023-03-19 15:08:21.944925: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 4530355200 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 15:08:23.470471: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inVGG6/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-03-19 15:08:23.922518: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-03-19 15:08:24.364273: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.85GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-19 15:08:24.364290: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.85GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-19 15:08:24.703466: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-19 15:08:24.703487: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-19 15:08:24.724554: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-19 15:08:24.724565: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-19 15:08:24.724570: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-19 15:08:24.724573: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-19 15:08:24.738415: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.13GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-19 15:08:24.738425: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.13GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-19 15:08:24.817521: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-03-19 15:08:24.822751: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x151e566e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-19 15:08:24.822773: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Ti, Compute Capability 8.6\n",
      "2023-03-19 15:08:24.826873: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-19 15:08:24.912255: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-03-19 15:08:25.931547: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 20s 126ms/step - loss: 0.9160 - accuracy: 0.2771\n",
      "Epoch 2/20\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 0.4802 - accuracy: 0.5481\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 0.4234 - accuracy: 0.5755\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 0.3847 - accuracy: 0.6013\n",
      "Epoch 5/20\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 0.3733 - accuracy: 0.6012\n",
      "Epoch 6/20\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 0.3683 - accuracy: 0.6014\n",
      "Epoch 7/20\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 0.3652 - accuracy: 0.6014\n",
      "Epoch 8/20\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 0.3562 - accuracy: 0.6015\n",
      "Epoch 9/20\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 0.3520 - accuracy: 0.6017\n",
      "Epoch 10/20\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 0.3499 - accuracy: 0.6013\n",
      "Epoch 11/20\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 0.3451 - accuracy: 0.6012\n",
      "Epoch 12/20\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 0.3402 - accuracy: 0.6015\n",
      "Epoch 13/20\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 0.3357 - accuracy: 0.6015\n",
      "Epoch 14/20\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 0.3323 - accuracy: 0.6014\n",
      "Epoch 15/20\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 0.3280 - accuracy: 0.6014\n",
      "Epoch 16/20\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 0.3251 - accuracy: 0.6017\n",
      "Epoch 17/20\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 0.3229 - accuracy: 0.6017\n",
      "Epoch 18/20\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 0.3191 - accuracy: 0.6017\n",
      "Epoch 19/20\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 0.3169 - accuracy: 0.6015\n",
      "Epoch 20/20\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 0.3172 - accuracy: 0.6013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 15:13:44.777299: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1415736000 exceeds 10% of free system memory.\n",
      "2023-03-19 15:13:45.611045: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1415736000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train model for 20 epochs\n",
    "n_epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "final_model_history = final_model.fit(\n",
    "    data_train,\n",
    "    class_train,\n",
    "    epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    "    validation_data=None,\n",
    "    shuffle=True,\n",
    ")\n",
    "classes = final_model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dce767cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.010747  , 0.982675  , 0.006578  , 0.982675  , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.086518  , 0.913482  ,\n",
       "        0.        , 0.        , 0.010747  , 0.        , 0.        ,\n",
       "        0.        , 0.043259  , 0.043259  , 0.        , 0.        ,\n",
       "        0.68686919, 0.26733084, 0.02847497, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]),\n",
       " array([0.005921  , 0.994079  , 0.        , 0.02775866, 0.96632034,\n",
       "        0.85074843, 0.11557191, 0.86417448, 0.10214586, 0.01704106,\n",
       "        0.37482889, 0.57445038, 0.        , 0.167988  , 0.832012  ,\n",
       "        0.        , 0.005921  , 0.        , 0.09675907, 0.        ,\n",
       "        0.02645643, 0.02573425, 0.01903825, 0.        , 0.        ,\n",
       "        0.02775866, 0.        , 0.        , 0.20598204, 0.5408652 ,\n",
       "        0.11732724, 0.04033534, 0.74710822, 0.        , 0.        ,\n",
       "        0.        , 0.07673178]),\n",
       " array([0.123004  , 0.870797  , 0.0062    , 0.14121976, 0.72957724,\n",
       "        0.16007581, 0.56950143, 0.2985182 , 0.43105904, 0.        ,\n",
       "        0.08579026, 0.58308397, 0.06070301, 0.358254  , 0.641746  ,\n",
       "        0.00819982, 0.06800092, 0.04680327, 0.358254  , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.12127544, 0.01994433, 0.        , 0.19156002, 0.09102178,\n",
       "        0.01593639, 0.        , 0.15793344, 0.        , 0.        ,\n",
       "        0.        , 0.14058476]),\n",
       " array([0.612854  , 0.387146  , 0.        , 0.        , 0.387146  ,\n",
       "        0.        , 0.387146  , 0.        , 0.387146  , 0.        ,\n",
       "        0.07643153, 0.31071447, 0.        , 0.175424  , 0.824576  ,\n",
       "        0.07981504, 0.53303896, 0.        , 0.03894413, 0.01947206,\n",
       "        0.        , 0.        , 0.11700781, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]),\n",
       " (8400, 37))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_train[0,:], class_train[26,:], class_train[135,:], class_train[6,:], class_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d61cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a10789d11d8c67e98bd9d36939f7ef03652b69216f681e3f86f003592db452c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
